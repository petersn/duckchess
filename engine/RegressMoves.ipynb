{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3d08942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"ml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf0b86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import make_dataset2 as make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a38019e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca716864",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e8e9d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EWMA:\n",
    "    def __init__(self, alpha=0.02):\n",
    "        self.alpha = alpha\n",
    "        self.value = None\n",
    "\n",
    "    def apply(self, x):\n",
    "        self.value = x if self.value is None else (1 - self.alpha) * self.value + self.alpha * x"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4bcc360d",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "def load_games(games):\n",
    "    features, policy, value = make_dataset.process_game_paths(games)\n",
    "\n",
    "    # Project down to just the duck moves\n",
    "    #is_duck_move = features[:, 14, 0, 0] == 1\n",
    "    dm_features = features#[is_duck_move]\n",
    "    dm_policy = policy#[is_duck_move]\n",
    "\n",
    "    # Our features are, in order:\n",
    "    # A Six channels for our pieces: pawns, knights, bishops, rooks, queens, kings\n",
    "    # A Six channels for their pieces.\n",
    "    # A One channel for ducks.\n",
    "    # 1 One channel that's all ones if it's white to move, zeros otherwise.\n",
    "    # 0 One channel for if it's the duck subturn.\n",
    "    # 1 Two channels for our castling rights: king side, queen side\n",
    "    # 1 Two channels for their castling rights.\n",
    "    # A One channel for an en passant square.\n",
    "    # A Pairs of (from, to) channels for the history of moves.\n",
    "    # 0 One channel of all ones.\n",
    "\n",
    "    all_layer_indices = (\n",
    "        0, 1, 2, 3,  4,  5, # Our pieces\n",
    "        6, 7, 8, 9, 10, 11, # Their pieces\n",
    "        12, # Ducks\n",
    "        14, # Is duck subturn -- too many features\n",
    "        19, # En passant\n",
    "        20, 21, 22, 23, 24, 25, 26, 27, # Past moves\n",
    "    )\n",
    "    all_layers = dm_features[:, all_layer_indices, :, :]\n",
    "\n",
    "    # Flatten features.\n",
    "    dm_features = all_layers.reshape((-1, 23 * 8 * 8))\n",
    "    # Find the move indices.\n",
    "    dm_policy = dm_policy.reshape((-1, 64 * 64)).argmax(axis=-1)\n",
    "    # Get just the destination square by taking %64.\n",
    "    dm_policy = dm_policy % 64\n",
    "    return dm_features, dm_policy\n",
    "\n",
    "dm_features, dm_policy = load_games(random.sample(glob.glob(\"games/*.json\"), 32))\n",
    "dm_val_features, dm_val_policy = load_games(glob.glob(\"val-games/*.json\"))\n",
    "dm_val_features = torch.tensor(dm_val_features, dtype=torch.float32, device=device)\n",
    "dm_val_policy = torch.tensor(dm_val_policy, dtype=torch.int64, device=device)\n",
    "\n",
    "print(dm_features.shape, dm_policy.shape)\n",
    "print(dm_val_features.shape, dm_val_policy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8550f846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.06 s, sys: 344 ms, total: 6.4 s\n",
      "Wall time: 6.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dm_train = np.load(\"dm_train.npz\")\n",
    "dm_features = dm_train[\"features\"]\n",
    "dm_policy = dm_train[\"policy_to\"]\n",
    "dm_value = dm_train[\"value\"]\n",
    "dm_val_train = np.load(\"dm_val.npz\")\n",
    "dm_val_features = dm_val_train[\"features\"]\n",
    "dm_val_policy = dm_val_train[\"policy_to\"]\n",
    "dm_val_value = dm_val_train[\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b022107",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped = dm_features.reshape(-1, 15, 8, 8)\n",
    "is_white_turn = reshaped[:, -2, 0, 0]\n",
    "is_duck_move = reshaped[:, -1, 0, 0]\n",
    "dm_features = reshaped[:, :-2].reshape(-1, 13 * 8 * 8)\n",
    "\n",
    "reshaped = dm_val_features.reshape(-1, 15, 8, 8)\n",
    "val_is_white_turn = reshaped[:, -2, 0, 0]\n",
    "val_is_duck_move = reshaped[:, -1, 0, 0]\n",
    "dm_val_features = reshaped[:, :-2].reshape(-1, 13 * 8 * 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d44cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_val_features = torch.tensor(dm_val_features, dtype=torch.float32, device=device)\n",
    "dm_val_policy = torch.tensor(dm_val_policy, dtype=torch.int64, device=device)\n",
    "dm_val_value = torch.tensor(dm_val_value, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7bee4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5772379, 832)\n",
      "(5772379,)\n",
      "(5772379, 1)\n",
      "torch.Size([21997, 832])\n",
      "torch.Size([21997])\n",
      "torch.Size([21997, 1])\n"
     ]
    }
   ],
   "source": [
    "print(dm_features.shape)\n",
    "print(dm_policy.shape)\n",
    "print(dm_value.shape)\n",
    "print(dm_val_features.shape)\n",
    "print(dm_val_policy.shape)\n",
    "print(dm_val_value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68f8a1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 52724\n"
     ]
    }
   ],
   "source": [
    "feature_count = dm_features.shape[1]\n",
    "\n",
    "class MultiModel(torch.nn.Module):\n",
    "    FEATS = 48\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main_embed = torch.nn.Linear(feature_count, self.FEATS)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.white_main = torch.nn.Linear(self.FEATS, 64 + 1)\n",
    "        self.black_main = torch.nn.Linear(self.FEATS, 64 + 1)\n",
    "        self.white_duck = torch.nn.Linear(self.FEATS, 64 + 1)\n",
    "        self.black_duck = torch.nn.Linear(self.FEATS, 64 + 1)\n",
    "\n",
    "    def forward(self, inputs, which_model):\n",
    "        embedding = self.main_embed(inputs)\n",
    "        embedding = self.relu(embedding)\n",
    "        white_main = self.white_main(embedding)\n",
    "        black_main = self.black_main(embedding)\n",
    "        white_duck = self.white_duck(embedding)\n",
    "        black_duck = self.black_duck(embedding)\n",
    "        data = torch.stack([white_main, black_main, white_duck, black_duck])\n",
    "        return data[which_model, torch.arange(len(which_model))]\n",
    "\n",
    "model = MultiModel()\n",
    "\n",
    "print(\"Parameters:\", sum(np.product(t.shape) for t in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8c070db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_en = torch.nn.CrossEntropyLoss()\n",
    "mse_func = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4)\n",
    "policy_loss_ewma = EWMA()\n",
    "value_loss_ewma = EWMA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "859315a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in optimizer.param_groups:\n",
    "    g['lr'] = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64ae5051",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(    0.0) [      0] loss = 3.5305 (policy = 2.9413  value = 0.5892) (val acc:  23.9%)\n",
      "(    4.8) [   2500] loss = 3.5233 (policy = 2.9340  value = 0.5892) (val acc:  24.2%)\n",
      "(    9.4) [   5000] loss = 3.5350 (policy = 2.9476  value = 0.5874) (val acc:  24.1%)\n",
      "(   14.0) [   7500] loss = 3.5370 (policy = 2.9509  value = 0.5861) (val acc:  24.2%)\n",
      "(   18.6) [  10000] loss = 3.5358 (policy = 2.9475  value = 0.5883) (val acc:  24.0%)\n",
      "(   23.0) [  12500] loss = 3.5197 (policy = 2.9314  value = 0.5883) (val acc:  24.1%)\n",
      "(   27.7) [  15000] loss = 3.5345 (policy = 2.9447  value = 0.5898) (val acc:  24.1%)\n",
      "(   32.2) [  17500] loss = 3.5295 (policy = 2.9439  value = 0.5856) (val acc:  24.0%)\n",
      "(   36.8) [  20000] loss = 3.5314 (policy = 2.9444  value = 0.5870) (val acc:  24.3%)\n",
      "(   41.5) [  22500] loss = 3.5389 (policy = 2.9518  value = 0.5870) (val acc:  24.2%)\n",
      "(   46.6) [  25000] loss = 3.5366 (policy = 2.9541  value = 0.5825) (val acc:  24.1%)\n",
      "(   51.1) [  27500] loss = 3.5364 (policy = 2.9481  value = 0.5884) (val acc:  24.0%)\n",
      "(   55.9) [  30000] loss = 3.5322 (policy = 2.9442  value = 0.5880) (val acc:  24.2%)\n",
      "(   60.4) [  32500] loss = 3.5318 (policy = 2.9446  value = 0.5872) (val acc:  24.1%)\n",
      "(   65.2) [  35000] loss = 3.5394 (policy = 2.9487  value = 0.5907) (val acc:  24.1%)\n",
      "(   69.9) [  37500] loss = 3.5307 (policy = 2.9407  value = 0.5900) (val acc:  24.2%)\n",
      "(   74.8) [  40000] loss = 3.5378 (policy = 2.9517  value = 0.5861) (val acc:  24.3%)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_594590/524407990.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mpolicy_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mvalue_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_594590/1756370015.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, which_model)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mwhite_main\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhite_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dm_val_which_model = 2 * val_is_duck_move + (1 - val_is_white_turn)\n",
    "\n",
    "def make_batch(batch_size):\n",
    "    indices = np.random.randint(0, len(dm_features), size=batch_size)\n",
    "    features = torch.tensor(dm_features[indices], dtype=torch.float32, device=device)\n",
    "    policy = torch.tensor(dm_policy[indices], dtype=torch.int64, device=device)\n",
    "    value = torch.tensor(dm_value[indices], dtype=torch.float32, device=device)\n",
    "    which_model = torch.tensor(\n",
    "        2 * is_duck_move[indices] + (1 - is_white_turn[indices]),\n",
    "        dtype=torch.int64,\n",
    "        device=device,\n",
    "    )\n",
    "    return features, policy, value, which_model\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(1_000_000):\n",
    "    optimizer.zero_grad()\n",
    "    features, target_policy, target_value, which_model = make_batch(512)\n",
    "    outputs = model(features, which_model)\n",
    "    policy_output = outputs[:, :64]\n",
    "    value_output = outputs[:, 64:]\n",
    "    policy_loss = cross_en(policy_output, target_policy)\n",
    "    value_loss = mse_func(value_output, target_value)\n",
    "    loss = policy_loss + value_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    policy_loss_ewma.apply(policy_loss.item())\n",
    "    value_loss_ewma.apply(value_loss.item())\n",
    "\n",
    "    if i % 2500 == 0:\n",
    "        # Compute the accuracy.\n",
    "        outputs = model(dm_val_features, dm_val_which_model)\n",
    "        val_policy_output = outputs[:, :64]\n",
    "        val_value_output = outputs[:, 64:]\n",
    "\n",
    "        correct = val_policy_output.argmax(axis=-1) == dm_val_policy\n",
    "        accuracy = correct.mean(dtype=torch.float32).item()\n",
    "        print(\"(%7.1f) [%7i] loss = %.4f (policy = %.4f  value = %0.4f) (val acc: %5.1f%%)\" % (\n",
    "            time.time() - start_time,\n",
    "            i,\n",
    "            policy_loss_ewma.value + value_loss_ewma.value,\n",
    "            policy_loss_ewma.value,\n",
    "            value_loss_ewma.value,\n",
    "            100 * accuracy,\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c56d38c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"multi-model-feat48-001.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de50b3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), \"move_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d584062d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight torch.Size([32, 1472])\n",
      "0.bias torch.Size([32])\n",
      "2.weight torch.Size([64, 32])\n",
      "2.bias torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for k, v in model.state_dict().items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b9062c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = model.state_dict()[\"0.weight\"].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94bc035f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(W.flatten(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b845cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8015668"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(W).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e979387",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wi = (W * 1000).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b901650b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2,    7,    0, ..., -625, -385, -311],\n",
       "       [ -14,   -7,  -13, ...,  326,   56, -207],\n",
       "       [  -5,   17,  -10, ..., -622, -306, -556],\n",
       "       ...,\n",
       "       [   6,    3,  -13, ...,  -70,  -71, -163],\n",
       "       [   6,  -10,    6, ..., -414, -375, -323],\n",
       "       [  13,  -17,  -16, ..., -288,   17,  -83]], dtype=int32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wi"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7772764",
   "metadata": {},
   "source": [
    "Performance:\n",
    "features -> 64                   --  29.5%\n",
    "features -> 64 -> 64             --  32.1%\n",
    "features -> 128 -> 64            --  35.7%\n",
    "features -> 128 -> 128 -> 64     --  35.9%\n",
    "features -> 1024 -> 64           --  40.8%\n",
    "features -> 48 -> 96 -> 96 -> 64 --  31.7%\n",
    "features -> 32 -> 64             --  27.1%\n",
    "features -> 32 -> 96 -> 64       --  29.0%\n",
    "\n",
    "New performances (four networks, both move kinds):\n",
    "features -> 64 -> 64 -> 65       --  31.5%\n",
    "features -> 64 -> 65             --  29.5%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0dbcc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "cases = 4\n",
    "features = 64\n",
    "\n",
    "# Generate some fake data.\n",
    "data = torch.tensor(np.random.randn(cases, batch_size, features))\n",
    "idx = torch.tensor(np.random.randint(low=0, high=cases, size=batch_size))\n",
    "\n",
    "# Index into the data of shape [batch_size, cases, features], getting a result of shape [batch_size, features].\n",
    "# This is the same as:\n",
    "#   result = np.zeros((batch_size, features))\n",
    "#   for i in range(batch_size):\n",
    "#       result[i] = data[i, idx[i]]\n",
    "result = data[idx, torch.arange(batch_size)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79a66550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 64])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4716e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 1, 2, 1, 1, 1, 0, 1, 0, 3, 1, 0, 0, 0, 2, 2, 2, 1, 1, 0, 0, 3, 3, 3,\n",
       "        1, 1, 1, 3, 0, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "234bf354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0] == data[3, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b69de53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
