{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d9ab4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"ml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b31d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import make_dataset2 as make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d88041e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03002db",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98058701",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EWMA:\n",
    "    def __init__(self, alpha=0.02):\n",
    "        self.alpha = alpha\n",
    "        self.value = None\n",
    "\n",
    "    def apply(self, x):\n",
    "        self.value = x if self.value is None else (1 - self.alpha) * self.value + self.alpha * x"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4bcc360d",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "def load_games(games):\n",
    "    features, policy, value = make_dataset.process_game_paths(games)\n",
    "\n",
    "    # Project down to just the duck moves\n",
    "    #is_duck_move = features[:, 14, 0, 0] == 1\n",
    "    dm_features = features#[is_duck_move]\n",
    "    dm_policy = policy#[is_duck_move]\n",
    "    dm_value = value\n",
    "\n",
    "    # Our features are, in order:\n",
    "    # A Six channels for our pieces: pawns, knights, bishops, rooks, queens, kings\n",
    "    # A Six channels for their pieces.\n",
    "    # A One channel for ducks.\n",
    "    # 1 One channel that's all ones if it's white to move, zeros otherwise.\n",
    "    # 0 One channel for if it's the duck subturn.\n",
    "    # 1 Two channels for our castling rights: king side, queen side\n",
    "    # 1 Two channels for their castling rights.\n",
    "    # A One channel for an en passant square.\n",
    "    # A Pairs of (from, to) channels for the history of moves.\n",
    "    # 0 One channel of all ones.\n",
    "\n",
    "    all_layer_indices = (\n",
    "        0, 1, 2, 3,  4,  5, # Our pieces\n",
    "        6, 7, 8, 9, 10, 11, # Their pieces\n",
    "        12, # Ducks\n",
    "        13,\n",
    "        14, # Is duck subturn -- too many features\n",
    "        #19, # En passant\n",
    "        #20, 21, 22, 23, 24, 25, 26, 27, # Past moves\n",
    "    )\n",
    "    all_layers = dm_features[:, all_layer_indices, :, :]\n",
    "\n",
    "    # Flatten features.\n",
    "    dm_features = all_layers.reshape((-1, 15 * 8 * 8))\n",
    "    # Find the move indices.\n",
    "    dm_policy = dm_policy.reshape((-1, 64 * 64)).argmax(axis=-1)\n",
    "    # Get just the destination square by taking %64.\n",
    "    dm_policy_to = dm_policy % 64\n",
    "    dm_policy_from = dm_policy // 64\n",
    "    return dm_features, dm_policy_to, dm_policy_from, dm_value\n",
    "\n",
    "dm_features, dm_policy_to, dm_policy_from, dm_value = load_games(random.sample(glob.glob(\"games/*.json\"), 100))\n",
    "dm_val_features, dm_val_policy_to, dm_val_policy_from, dm_val_value = load_games(glob.glob(\"val-games/*.json\"))\n",
    "#dm_val_features = torch.tensor(dm_val_features, dtype=torch.float32, device=device)\n",
    "#dm_val_policy = torch.tensor(dm_val_policy, dtype=torch.int64, device=device)\n",
    "\n",
    "print(dm_features.shape, dm_policy_to.shape)\n",
    "print(dm_val_features.shape, dm_val_policy_to.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e389f1c2",
   "metadata": {},
   "source": [
    "%%time\n",
    "np.savez_compressed(\"dm_train.npz\", features=dm_features, policy_to=dm_policy_to, policy_from=dm_policy_from, value=dm_value)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c08fe06c",
   "metadata": {},
   "source": [
    "%%time\n",
    "np.savez_compressed(\"dm_val.npz\", features=dm_val_features, policy_to=dm_val_policy_to, policy_from=dm_val_policy_from, value=dm_val_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10d21de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dm_train = np.load(\"dm_train.npz\")\n",
    "dm_features = torch.tensor(dm_train[\"features\"])\n",
    "dm_policy_to = torch.tensor(dm_train[\"policy_to\"])\n",
    "dm_policy_from = torch.tensor(dm_train[\"policy_from\"])\n",
    "dm_value = torch.tensor(dm_train[\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6014099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_white_turn = dm_features.reshape(-1, 15, 8, 8)[:, 13, 0, 0]\n",
    "is_duck_move = dm_features.reshape(-1, 15, 8, 8)[:, 14, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e629753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dm_val = np.load(\"dm_val.npz\")\n",
    "dm_val_features = torch.tensor(dm_val[\"features\"], dtype=torch.float32, device=device)\n",
    "dm_val_policy_to = torch.tensor(dm_val[\"policy_to\"], dtype=torch.float32, device=device)\n",
    "dm_val_policy_from = torch.tensor(dm_val[\"policy_from\"], dtype=torch.float32, device=device)\n",
    "dm_val_value = torch.tensor(dm_val[\"value\"], dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e403d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_is_white_turn = dm_val_features.reshape(-1, 15, 8, 8)[:, 13, 0, 0].to(torch.int64)\n",
    "val_is_duck_move = dm_val_features.reshape(-1, 15, 8, 8)[:, 14, 0, 0].to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08c0197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we make the important decision to predict\n",
    "# the target squares of moves, not source squares.\n",
    "dm_policy = dm_policy_to\n",
    "dm_val_policy = dm_val_policy_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37443f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_count = dm_features.shape[1]\n",
    "\n",
    "class MultiModel(torch.nn.Module):\n",
    "    ACCUM_SIZE = 256\n",
    "    SIZE1 = 16\n",
    "    SIZE2 = 32\n",
    "    FINAL_SIZE = 1\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main_embed = torch.nn.Linear(feature_count, self.ACCUM_SIZE)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        make_net = lambda: torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.ACCUM_SIZE, self.SIZE1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(self.SIZE1, self.SIZE2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(self.SIZE2, self.FINAL_SIZE),\n",
    "        )\n",
    "        self.white_main = make_net()\n",
    "        self.black_main = make_net()\n",
    "        self.white_duck = make_net()\n",
    "        self.black_duck = make_net()\n",
    "\n",
    "    def forward(self, inputs, which_model):\n",
    "        embedding = self.main_embed(inputs)\n",
    "        embedding = self.relu(embedding)\n",
    "        white_main = self.white_main(embedding)\n",
    "        black_main = self.black_main(embedding)\n",
    "        white_duck = self.white_duck(embedding)\n",
    "        black_duck = self.black_duck(embedding)\n",
    "        data = torch.stack([white_main, black_main, white_duck, black_duck])\n",
    "        data = data[which_model, torch.arange(len(which_model))]\n",
    "        #policy = data[:, :64]\n",
    "        #value = data[:, 64:]\n",
    "        value = data[:, :1]\n",
    "        return None, self.tanh(value)\n",
    "        #return policy, self.tanh(value)\n",
    "\n",
    "model = MultiModel()\n",
    "\n",
    "print(\"Parameters:\", sum(np.product(t.shape) for t in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c070db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_en = torch.nn.CrossEntropyLoss()\n",
    "mse_func = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "policy_loss_ewma = EWMA()\n",
    "value_loss_ewma = EWMA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d0bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in optimizer.param_groups:\n",
    "    g['lr'] = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ae5051",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dm_val_which_model = 2 * val_is_duck_move + (1 - val_is_white_turn)\n",
    "\n",
    "def make_batch(batch_size):\n",
    "    indices = np.random.randint(0, len(dm_features), size=batch_size)\n",
    "    features = torch.tensor(dm_features[indices], dtype=torch.float32, device=device)\n",
    "    policy = torch.tensor(dm_policy[indices], dtype=torch.int64, device=device)\n",
    "    value = torch.tensor(dm_value[indices], dtype=torch.float32, device=device)\n",
    "    which_model = torch.tensor(\n",
    "        2 * is_duck_move[indices] + (1 - is_white_turn[indices]),\n",
    "        dtype=torch.int64,\n",
    "        device=device,\n",
    "    )\n",
    "    return features, policy, value, which_model\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(1_000_000):\n",
    "    optimizer.zero_grad()\n",
    "    features, target_policy, target_value, which_model = make_batch(512)\n",
    "    policy_output, value_output = model(features, which_model)\n",
    "    #policy_loss = cross_en(policy_output, target_policy)\n",
    "    policy_loss = torch.tensor(0)\n",
    "    value_loss = mse_func(value_output, target_value)\n",
    "    loss = policy_loss + value_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    policy_loss_ewma.apply(policy_loss.item())\n",
    "    value_loss_ewma.apply(value_loss.item())\n",
    "\n",
    "    if i % 2500 == 0:\n",
    "        # Compute the accuracy.\n",
    "        val_policy_output, val_value_output = model(dm_val_features, dm_val_which_model)\n",
    "        #correct = val_policy_output.argmax(axis=-1) == dm_val_policy\n",
    "        #accuracy = correct.mean(dtype=torch.float32).item()\n",
    "        correct = 0\n",
    "        accuracy = 0\n",
    "        print(\"(%7.1f) [%7i] loss = %.4f (policy = %.4f  value = %0.4f) (val acc: %5.1f%%)\" % (\n",
    "            time.time() - start_time,\n",
    "            i,\n",
    "            policy_loss_ewma.value + value_loss_ewma.value,\n",
    "            policy_loss_ewma.value,\n",
    "            value_loss_ewma.value,\n",
    "            100 * accuracy,\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc5c0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for weight in model.parameters():\n",
    "    print(weight.min().item(), weight.max().item(), weight.mean().item(), weight.var().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bea8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"multi-model-nonsense.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc68a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), \"move_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd58c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in model.state_dict().items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77269b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = model.state_dict()[\"0.weight\"].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b879853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(W.flatten(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d55e264",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(W).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda2b284",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wi = (W * 1000).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab007449",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wi"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7772764",
   "metadata": {},
   "source": [
    "Performance:\n",
    "features -> 64                   --  29.5%\n",
    "features -> 64 -> 64             --  32.1%\n",
    "features -> 128 -> 64            --  35.7%\n",
    "features -> 128 -> 128 -> 64     --  35.9%\n",
    "features -> 1024 -> 64           --  40.8%\n",
    "features -> 48 -> 96 -> 96 -> 64 --  31.7%\n",
    "features -> 32 -> 64             --  27.1%\n",
    "features -> 32 -> 96 -> 64       --  29.0%\n",
    "\n",
    "New performances (four networks, both move kinds):\n",
    "features -> 64 -> 64 -> 65       --  31.5%\n",
    "features -> 64 -> 65             --  29.5%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dbcc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "cases = 4\n",
    "features = 64\n",
    "\n",
    "# Generate some fake data.\n",
    "data = torch.tensor(np.random.randn(cases, batch_size, features))\n",
    "idx = torch.tensor(np.random.randint(low=0, high=cases, size=batch_size))\n",
    "\n",
    "# Index into the data of shape [batch_size, cases, features], getting a result of shape [batch_size, features].\n",
    "# This is the same as:\n",
    "#   result = np.zeros((batch_size, features))\n",
    "#   for i in range(batch_size):\n",
    "#       result[i] = data[i, idx[i]]\n",
    "result = data[idx, torch.arange(batch_size)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a66550",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4716e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234bf354",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0] == data[3, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b69de53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
