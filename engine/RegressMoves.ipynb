{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3d08942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"ml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf0b86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import make_dataset2 as make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a38019e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca716864",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e8e9d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EWMA:\n",
    "    def __init__(self, alpha=0.02):\n",
    "        self.alpha = alpha\n",
    "        self.value = None\n",
    "\n",
    "    def apply(self, x):\n",
    "        self.value = x if self.value is None else (1 - self.alpha) * self.value + self.alpha * x"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4bcc360d",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "def load_games(games):\n",
    "    features, policy, value = make_dataset.process_game_paths(games)\n",
    "\n",
    "    # Project down to just the duck moves\n",
    "    #is_duck_move = features[:, 14, 0, 0] == 1\n",
    "    dm_features = features#[is_duck_move]\n",
    "    dm_policy = policy#[is_duck_move]\n",
    "\n",
    "    # Our features are, in order:\n",
    "    # A Six channels for our pieces: pawns, knights, bishops, rooks, queens, kings\n",
    "    # A Six channels for their pieces.\n",
    "    # A One channel for ducks.\n",
    "    # 1 One channel that's all ones if it's white to move, zeros otherwise.\n",
    "    # 0 One channel for if it's the duck subturn.\n",
    "    # 1 Two channels for our castling rights: king side, queen side\n",
    "    # 1 Two channels for their castling rights.\n",
    "    # A One channel for an en passant square.\n",
    "    # A Pairs of (from, to) channels for the history of moves.\n",
    "    # 0 One channel of all ones.\n",
    "\n",
    "    all_layer_indices = (\n",
    "        0, 1, 2, 3,  4,  5, # Our pieces\n",
    "        6, 7, 8, 9, 10, 11, # Their pieces\n",
    "        12, # Ducks\n",
    "        14, # Is duck subturn -- too many features\n",
    "        19, # En passant\n",
    "        20, 21, 22, 23, 24, 25, 26, 27, # Past moves\n",
    "    )\n",
    "    all_layers = dm_features[:, all_layer_indices, :, :]\n",
    "\n",
    "    # Flatten features.\n",
    "    dm_features = all_layers.reshape((-1, 23 * 8 * 8))\n",
    "    # Find the move indices.\n",
    "    dm_policy = dm_policy.reshape((-1, 64 * 64)).argmax(axis=-1)\n",
    "    # Get just the destination square by taking %64.\n",
    "    dm_policy = dm_policy % 64\n",
    "    return dm_features, dm_policy\n",
    "\n",
    "dm_features, dm_policy = load_games(random.sample(glob.glob(\"games/*.json\"), 32))\n",
    "dm_val_features, dm_val_policy = load_games(glob.glob(\"val-games/*.json\"))\n",
    "dm_val_features = torch.tensor(dm_val_features, dtype=torch.float32, device=device)\n",
    "dm_val_policy = torch.tensor(dm_val_policy, dtype=torch.int64, device=device)\n",
    "\n",
    "print(dm_features.shape, dm_policy.shape)\n",
    "print(dm_val_features.shape, dm_val_policy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8550f846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.04 s, sys: 273 ms, total: 6.31 s\n",
      "Wall time: 6.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dm_train = np.load(\"dm_train.npz\")\n",
    "dm_features_orig = dm_train[\"features\"]\n",
    "dm_policy = dm_train[\"policy_to\"]\n",
    "dm_value = dm_train[\"value\"]\n",
    "dm_val_train = np.load(\"dm_val.npz\")\n",
    "dm_val_features_orig = dm_val_train[\"features\"]\n",
    "dm_val_policy = dm_val_train[\"policy_to\"]\n",
    "dm_val_value = dm_val_train[\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29b22b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our features are currently in the order:\n",
    "#   (\n",
    "#     6 layers of our pieces us on bottom,\n",
    "#     6 layers of their pieces us on bottom,\n",
    "#     ducks,\n",
    "#     is_white,\n",
    "#     is_duck_turn,\n",
    "#   )\n",
    "# We want it in the order:\n",
    "#   (\n",
    "#     6 layers of black pieces white on bottom,\n",
    "#     6 layers of white pieces white on bottom,\n",
    "#     duck,\n",
    "#   )\n",
    "def patch_up_features(feats):\n",
    "    _, a, b, c = feats.shape\n",
    "    assert (a, b, c) == (15, 8, 8)\n",
    "    # feats of shape [batch, 15, 8, 8]\n",
    "    # is_white_turn of shape [batch]\n",
    "    is_white_turn = feats[:, -2, 0, 0]\n",
    "    \n",
    "    # If we're black then they're in order (black pieces black bottom, white pieces black bottom)\n",
    "    # We want to convert this into (black pieces white bottom, white pieces white bottom)\n",
    "    if_black = feats[:, :-2].copy()\n",
    "    if_black[:, :, :, :] = feats[:, :-2, ::-1, :]\n",
    "\n",
    "    # If we're white then they're in the order (white pieces white bottom, black pieces, white bottom)\n",
    "    # We want to just swap the two halves.\n",
    "    if_white = feats[:, :-2].copy()\n",
    "    if_white[:, :6, :, :] = feats[:, 6:12, :, :]\n",
    "    if_white[:, 6:12, :, :] = feats[:, :6, :, :]\n",
    "\n",
    "    return np.where(\n",
    "        is_white_turn.reshape(-1, 1, 1, 1),\n",
    "        if_white,\n",
    "        if_black,\n",
    "    ).reshape(-1, 13 * 8 * 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b022107",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped = dm_features_orig.reshape(-1, 15, 8, 8)\n",
    "is_white_turn = reshaped[:, -2, 0, 0]\n",
    "is_duck_move = reshaped[:, -1, 0, 0]\n",
    "dm_features = patch_up_features(reshaped)\n",
    "\n",
    "reshaped = dm_val_features_orig.reshape(-1, 15, 8, 8)\n",
    "val_is_white_turn = reshaped[:, -2, 0, 0]\n",
    "val_is_duck_move = reshaped[:, -1, 0, 0]\n",
    "dm_val_features = patch_up_features(reshaped) #reshaped[:, :-2].reshape(-1, 13 * 8 * 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d44cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_val_features = torch.tensor(dm_val_features, dtype=torch.float32, device=device)\n",
    "dm_val_policy = torch.tensor(dm_val_policy, dtype=torch.int64, device=device)\n",
    "dm_val_value = torch.tensor(dm_val_value, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7bee4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5772379, 832)\n",
      "(5772379,)\n",
      "(5772379, 1)\n",
      "torch.Size([21997, 832])\n",
      "torch.Size([21997])\n",
      "torch.Size([21997, 1])\n"
     ]
    }
   ],
   "source": [
    "print(dm_features.shape)\n",
    "print(dm_policy.shape)\n",
    "print(dm_value.shape)\n",
    "print(dm_val_features.shape)\n",
    "print(dm_val_policy.shape)\n",
    "print(dm_val_value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68f8a1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 181380\n"
     ]
    }
   ],
   "source": [
    "feature_count = dm_features.shape[1]\n",
    "\n",
    "class MultiModel(torch.nn.Module):\n",
    "    FEATS = 128\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main_embed = torch.nn.Linear(feature_count, self.FEATS)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        self.white_main = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.FEATS, 96),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(96, 64 + 1),\n",
    "        )\n",
    "        self.black_main = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.FEATS, 96),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(96, 64 + 1),\n",
    "        )\n",
    "        self.white_duck = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.FEATS, 96),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(96, 64 + 1),\n",
    "        )\n",
    "        self.black_duck = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.FEATS, 96),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(96, 64 + 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs, which_model):\n",
    "        embedding = self.main_embed(inputs)\n",
    "        embedding = self.relu(embedding)\n",
    "        white_main = self.white_main(embedding)\n",
    "        black_main = self.black_main(embedding)\n",
    "        white_duck = self.white_duck(embedding)\n",
    "        black_duck = self.black_duck(embedding)\n",
    "        data = torch.stack([white_main, black_main, white_duck, black_duck])\n",
    "        data = data[which_model, torch.arange(len(which_model))]\n",
    "        policy = data[:, :64]\n",
    "        value = data[:, 64:]\n",
    "        return policy, self.tanh(value)\n",
    "\n",
    "model = MultiModel()\n",
    "\n",
    "print(\"Parameters:\", sum(np.product(t.shape) for t in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8c070db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_en = torch.nn.CrossEntropyLoss()\n",
    "mse_func = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "policy_loss_ewma = EWMA()\n",
    "value_loss_ewma = EWMA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ace84b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in optimizer.param_groups:\n",
    "    g['lr'] = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64ae5051",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(    0.0) [      0] loss = 3.1746 (policy = 2.6327  value = 0.5419) (val acc:  29.7%)\n",
      "(   11.3) [   2500] loss = 3.1618 (policy = 2.6183  value = 0.5435) (val acc:  29.9%)\n",
      "(   22.8) [   5000] loss = 3.1546 (policy = 2.6177  value = 0.5369) (val acc:  30.1%)\n",
      "(   33.9) [   7500] loss = 3.1731 (policy = 2.6271  value = 0.5461) (val acc:  30.0%)\n",
      "(   44.9) [  10000] loss = 3.1546 (policy = 2.6126  value = 0.5420) (val acc:  30.1%)\n",
      "(   56.3) [  12500] loss = 3.1627 (policy = 2.6226  value = 0.5401) (val acc:  30.2%)\n",
      "(   67.3) [  15000] loss = 3.1582 (policy = 2.6169  value = 0.5414) (val acc:  30.2%)\n",
      "(   78.4) [  17500] loss = 3.1603 (policy = 2.6186  value = 0.5417) (val acc:  30.2%)\n",
      "(   89.8) [  20000] loss = 3.1499 (policy = 2.6131  value = 0.5368) (val acc:  30.3%)\n",
      "(  100.9) [  22500] loss = 3.1593 (policy = 2.6135  value = 0.5457) (val acc:  30.3%)\n",
      "(  112.0) [  25000] loss = 3.1497 (policy = 2.6089  value = 0.5408) (val acc:  30.1%)\n",
      "(  123.4) [  27500] loss = 3.1576 (policy = 2.6173  value = 0.5404) (val acc:  30.3%)\n",
      "(  134.5) [  30000] loss = 3.1497 (policy = 2.6105  value = 0.5392) (val acc:  30.2%)\n",
      "(  145.5) [  32500] loss = 3.1547 (policy = 2.6115  value = 0.5432) (val acc:  30.3%)\n",
      "(  156.7) [  35000] loss = 3.1648 (policy = 2.6241  value = 0.5408) (val acc:  30.3%)\n",
      "(  168.0) [  37500] loss = 3.1539 (policy = 2.6115  value = 0.5424) (val acc:  30.2%)\n",
      "(  179.3) [  40000] loss = 3.1526 (policy = 2.6127  value = 0.5399) (val acc:  30.1%)\n",
      "(  190.6) [  42500] loss = 3.1644 (policy = 2.6180  value = 0.5464) (val acc:  30.4%)\n",
      "(  201.8) [  45000] loss = 3.1547 (policy = 2.6147  value = 0.5401) (val acc:  30.2%)\n",
      "(  212.9) [  47500] loss = 3.1384 (policy = 2.5984  value = 0.5399) (val acc:  30.4%)\n",
      "(  224.0) [  50000] loss = 3.1499 (policy = 2.6091  value = 0.5408) (val acc:  30.3%)\n",
      "(  235.4) [  52500] loss = 3.1490 (policy = 2.6110  value = 0.5380) (val acc:  30.4%)\n",
      "(  246.6) [  55000] loss = 3.1565 (policy = 2.6148  value = 0.5417) (val acc:  30.4%)\n",
      "(  257.8) [  57500] loss = 3.1497 (policy = 2.6108  value = 0.5389) (val acc:  30.4%)\n",
      "(  269.2) [  60000] loss = 3.1390 (policy = 2.6029  value = 0.5361) (val acc:  30.4%)\n",
      "(  280.4) [  62500] loss = 3.1437 (policy = 2.6097  value = 0.5340) (val acc:  30.4%)\n",
      "(  291.6) [  65000] loss = 3.1546 (policy = 2.6077  value = 0.5469) (val acc:  30.6%)\n",
      "(  303.1) [  67500] loss = 3.1622 (policy = 2.6203  value = 0.5420) (val acc:  30.3%)\n",
      "(  314.3) [  70000] loss = 3.1476 (policy = 2.6111  value = 0.5366) (val acc:  30.4%)\n",
      "(  325.4) [  72500] loss = 3.1483 (policy = 2.6092  value = 0.5391) (val acc:  30.5%)\n",
      "(  336.9) [  75000] loss = 3.1504 (policy = 2.6145  value = 0.5359) (val acc:  30.2%)\n",
      "(  347.9) [  77500] loss = 3.1548 (policy = 2.6115  value = 0.5434) (val acc:  30.4%)\n",
      "(  359.0) [  80000] loss = 3.1529 (policy = 2.6109  value = 0.5420) (val acc:  30.3%)\n",
      "(  370.4) [  82500] loss = 3.1493 (policy = 2.6106  value = 0.5387) (val acc:  30.5%)\n",
      "(  381.6) [  85000] loss = 3.1511 (policy = 2.6029  value = 0.5483) (val acc:  30.5%)\n",
      "(  392.8) [  87500] loss = 3.1358 (policy = 2.5991  value = 0.5367) (val acc:  30.4%)\n",
      "(  403.9) [  90000] loss = 3.1565 (policy = 2.6131  value = 0.5434) (val acc:  30.5%)\n",
      "(  414.9) [  92500] loss = 3.1538 (policy = 2.6155  value = 0.5383) (val acc:  30.4%)\n",
      "(  425.6) [  95000] loss = 3.1493 (policy = 2.6068  value = 0.5425) (val acc:  30.4%)\n",
      "(  436.4) [  97500] loss = 3.1612 (policy = 2.6171  value = 0.5440) (val acc:  30.5%)\n",
      "(  447.0) [ 100000] loss = 3.1348 (policy = 2.5948  value = 0.5400) (val acc:  30.4%)\n",
      "(  458.1) [ 102500] loss = 3.1581 (policy = 2.6122  value = 0.5459) (val acc:  30.4%)\n",
      "(  468.9) [ 105000] loss = 3.1575 (policy = 2.6163  value = 0.5413) (val acc:  30.5%)\n",
      "(  479.8) [ 107500] loss = 3.1477 (policy = 2.6046  value = 0.5431) (val acc:  30.4%)\n",
      "(  490.2) [ 110000] loss = 3.1408 (policy = 2.6011  value = 0.5397) (val acc:  30.5%)\n",
      "(  500.5) [ 112500] loss = 3.1471 (policy = 2.6068  value = 0.5403) (val acc:  30.5%)\n",
      "(  511.5) [ 115000] loss = 3.1489 (policy = 2.6084  value = 0.5405) (val acc:  30.5%)\n",
      "(  522.0) [ 117500] loss = 3.1540 (policy = 2.6154  value = 0.5385) (val acc:  30.5%)\n",
      "(  532.4) [ 120000] loss = 3.1421 (policy = 2.6027  value = 0.5394) (val acc:  30.4%)\n",
      "(  543.3) [ 122500] loss = 3.1541 (policy = 2.6108  value = 0.5432) (val acc:  30.4%)\n",
      "(  553.7) [ 125000] loss = 3.1424 (policy = 2.6068  value = 0.5357) (val acc:  30.4%)\n",
      "(  564.1) [ 127500] loss = 3.1619 (policy = 2.6192  value = 0.5426) (val acc:  30.5%)\n",
      "(  574.6) [ 130000] loss = 3.1530 (policy = 2.6136  value = 0.5394) (val acc:  30.5%)\n",
      "(  585.5) [ 132500] loss = 3.1432 (policy = 2.6032  value = 0.5400) (val acc:  30.5%)\n",
      "(  596.2) [ 135000] loss = 3.1512 (policy = 2.6070  value = 0.5442) (val acc:  30.5%)\n",
      "(  608.7) [ 137500] loss = 3.1514 (policy = 2.6133  value = 0.5381) (val acc:  30.4%)\n",
      "(  620.2) [ 140000] loss = 3.1501 (policy = 2.6089  value = 0.5412) (val acc:  30.5%)\n",
      "(  631.1) [ 142500] loss = 3.1407 (policy = 2.5991  value = 0.5417) (val acc:  30.4%)\n",
      "(  642.0) [ 145000] loss = 3.1397 (policy = 2.5960  value = 0.5436) (val acc:  30.5%)\n",
      "(  653.2) [ 147500] loss = 3.1498 (policy = 2.6101  value = 0.5398) (val acc:  30.5%)\n",
      "(  664.0) [ 150000] loss = 3.1516 (policy = 2.6068  value = 0.5448) (val acc:  30.5%)\n",
      "(  774.1) [ 175000] loss = 3.1605 (policy = 2.6172  value = 0.5432) (val acc:  30.4%)\n",
      "(  785.4) [ 177500] loss = 3.1464 (policy = 2.6042  value = 0.5422) (val acc:  30.5%)\n",
      "(  796.4) [ 180000] loss = 3.1487 (policy = 2.6072  value = 0.5415) (val acc:  30.4%)\n",
      "(  807.3) [ 182500] loss = 3.1544 (policy = 2.6105  value = 0.5439) (val acc:  30.5%)\n",
      "(  818.8) [ 185000] loss = 3.1379 (policy = 2.5984  value = 0.5396) (val acc:  30.5%)\n",
      "(  829.7) [ 187500] loss = 3.1326 (policy = 2.5962  value = 0.5364) (val acc:  30.5%)\n",
      "(  840.4) [ 190000] loss = 3.1556 (policy = 2.6155  value = 0.5401) (val acc:  30.5%)\n",
      "(  851.7) [ 192500] loss = 3.1535 (policy = 2.6092  value = 0.5443) (val acc:  30.6%)\n",
      "(  862.6) [ 195000] loss = 3.1411 (policy = 2.6006  value = 0.5405) (val acc:  30.5%)\n",
      "(  873.4) [ 197500] loss = 3.1403 (policy = 2.6003  value = 0.5400) (val acc:  30.5%)\n",
      "(  884.2) [ 200000] loss = 3.1403 (policy = 2.6022  value = 0.5381) (val acc:  30.5%)\n",
      "(  895.3) [ 202500] loss = 3.1561 (policy = 2.6150  value = 0.5411) (val acc:  30.4%)\n",
      "(  906.1) [ 205000] loss = 3.1483 (policy = 2.6055  value = 0.5428) (val acc:  30.5%)\n",
      "(  916.9) [ 207500] loss = 3.1546 (policy = 2.6161  value = 0.5385) (val acc:  30.4%)\n",
      "(  928.3) [ 210000] loss = 3.1411 (policy = 2.5984  value = 0.5428) (val acc:  30.6%)\n",
      "(  939.3) [ 212500] loss = 3.1514 (policy = 2.6110  value = 0.5404) (val acc:  30.4%)\n",
      "(  950.1) [ 215000] loss = 3.1477 (policy = 2.6061  value = 0.5416) (val acc:  30.4%)\n",
      "(  961.4) [ 217500] loss = 3.1530 (policy = 2.6097  value = 0.5433) (val acc:  30.6%)\n",
      "(  972.4) [ 220000] loss = 3.1389 (policy = 2.6013  value = 0.5376) (val acc:  30.5%)\n",
      "(  983.4) [ 222500] loss = 3.1393 (policy = 2.5980  value = 0.5413) (val acc:  30.5%)\n",
      "(  994.7) [ 225000] loss = 3.1573 (policy = 2.6170  value = 0.5403) (val acc:  30.6%)\n",
      "( 1005.4) [ 227500] loss = 3.1445 (policy = 2.6087  value = 0.5357) (val acc:  30.5%)\n",
      "( 1015.6) [ 230000] loss = 3.1544 (policy = 2.6070  value = 0.5475) (val acc:  30.4%)\n",
      "( 1026.8) [ 232500] loss = 3.1247 (policy = 2.5867  value = 0.5379) (val acc:  30.6%)\n",
      "( 1038.1) [ 235000] loss = 3.1356 (policy = 2.5967  value = 0.5388) (val acc:  30.5%)\n",
      "( 1049.4) [ 237500] loss = 3.1419 (policy = 2.6010  value = 0.5409) (val acc:  30.4%)\n",
      "( 1060.7) [ 240000] loss = 3.1415 (policy = 2.5990  value = 0.5425) (val acc:  30.5%)\n",
      "( 1071.8) [ 242500] loss = 3.1527 (policy = 2.6153  value = 0.5374) (val acc:  30.4%)\n",
      "( 1083.1) [ 245000] loss = 3.1343 (policy = 2.5947  value = 0.5396) (val acc:  30.4%)\n",
      "( 1094.4) [ 247500] loss = 3.1425 (policy = 2.6035  value = 0.5390) (val acc:  30.4%)\n",
      "( 1105.8) [ 250000] loss = 3.1286 (policy = 2.5915  value = 0.5371) (val acc:  30.4%)\n",
      "( 1117.2) [ 252500] loss = 3.1589 (policy = 2.6180  value = 0.5409) (val acc:  30.4%)\n",
      "( 1128.6) [ 255000] loss = 3.1487 (policy = 2.6111  value = 0.5376) (val acc:  30.5%)\n",
      "( 1139.9) [ 257500] loss = 3.1354 (policy = 2.5980  value = 0.5374) (val acc:  30.6%)\n",
      "( 1151.2) [ 260000] loss = 3.1543 (policy = 2.6110  value = 0.5433) (val acc:  30.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 1162.5) [ 262500] loss = 3.1407 (policy = 2.6012  value = 0.5396) (val acc:  30.6%)\n",
      "( 1173.9) [ 265000] loss = 3.1412 (policy = 2.5951  value = 0.5461) (val acc:  30.3%)\n",
      "( 1185.3) [ 267500] loss = 3.1435 (policy = 2.6021  value = 0.5414) (val acc:  30.6%)\n",
      "( 1196.6) [ 270000] loss = 3.1419 (policy = 2.5974  value = 0.5446) (val acc:  30.5%)\n",
      "( 1208.0) [ 272500] loss = 3.1388 (policy = 2.5981  value = 0.5407) (val acc:  30.5%)\n",
      "( 1219.5) [ 275000] loss = 3.1513 (policy = 2.6100  value = 0.5412) (val acc:  30.5%)\n",
      "( 1230.8) [ 277500] loss = 3.1411 (policy = 2.6024  value = 0.5387) (val acc:  30.6%)\n",
      "( 1241.8) [ 280000] loss = 3.1472 (policy = 2.6063  value = 0.5409) (val acc:  30.5%)\n",
      "( 1253.5) [ 282500] loss = 3.1454 (policy = 2.6063  value = 0.5391) (val acc:  30.5%)\n",
      "( 1264.8) [ 285000] loss = 3.1482 (policy = 2.6095  value = 0.5387) (val acc:  30.6%)\n",
      "( 1276.0) [ 287500] loss = 3.1431 (policy = 2.6001  value = 0.5430) (val acc:  30.6%)\n",
      "( 1287.3) [ 290000] loss = 3.1399 (policy = 2.6036  value = 0.5363) (val acc:  30.7%)\n",
      "( 1298.5) [ 292500] loss = 3.1415 (policy = 2.6065  value = 0.5350) (val acc:  30.6%)\n",
      "( 1309.8) [ 295000] loss = 3.1462 (policy = 2.6087  value = 0.5374) (val acc:  30.6%)\n",
      "( 1321.2) [ 297500] loss = 3.1488 (policy = 2.6070  value = 0.5418) (val acc:  30.5%)\n",
      "( 1332.6) [ 300000] loss = 3.1357 (policy = 2.5930  value = 0.5426) (val acc:  30.5%)\n",
      "( 1343.9) [ 302500] loss = 3.1349 (policy = 2.5985  value = 0.5364) (val acc:  30.6%)\n",
      "( 1355.4) [ 305000] loss = 3.1526 (policy = 2.6128  value = 0.5398) (val acc:  30.5%)\n",
      "( 1366.6) [ 307500] loss = 3.1408 (policy = 2.6030  value = 0.5378) (val acc:  30.5%)\n",
      "( 1377.9) [ 310000] loss = 3.1396 (policy = 2.6025  value = 0.5370) (val acc:  30.6%)\n",
      "( 1389.3) [ 312500] loss = 3.1413 (policy = 2.6049  value = 0.5364) (val acc:  30.5%)\n",
      "( 1400.6) [ 315000] loss = 3.1522 (policy = 2.6110  value = 0.5412) (val acc:  30.6%)\n",
      "( 1412.1) [ 317500] loss = 3.1527 (policy = 2.6129  value = 0.5398) (val acc:  30.6%)\n",
      "( 1423.6) [ 320000] loss = 3.1527 (policy = 2.6131  value = 0.5395) (val acc:  30.5%)\n",
      "( 1435.1) [ 322500] loss = 3.1521 (policy = 2.6153  value = 0.5368) (val acc:  30.6%)\n",
      "( 1446.6) [ 325000] loss = 3.1361 (policy = 2.6020  value = 0.5341) (val acc:  30.6%)\n",
      "( 1457.9) [ 327500] loss = 3.1508 (policy = 2.6087  value = 0.5420) (val acc:  30.6%)\n",
      "( 1469.0) [ 330000] loss = 3.1408 (policy = 2.6054  value = 0.5354) (val acc:  30.6%)\n",
      "( 1480.3) [ 332500] loss = 3.1403 (policy = 2.6008  value = 0.5395) (val acc:  30.6%)\n",
      "( 1492.1) [ 335000] loss = 3.1251 (policy = 2.5880  value = 0.5371) (val acc:  30.6%)\n",
      "( 1503.4) [ 337500] loss = 3.1379 (policy = 2.5943  value = 0.5436) (val acc:  30.6%)\n",
      "( 1514.9) [ 340000] loss = 3.1311 (policy = 2.5919  value = 0.5393) (val acc:  30.6%)\n",
      "( 1526.4) [ 342500] loss = 3.1482 (policy = 2.6057  value = 0.5425) (val acc:  30.5%)\n",
      "( 1537.6) [ 345000] loss = 3.1527 (policy = 2.6109  value = 0.5418) (val acc:  30.5%)\n",
      "( 1548.9) [ 347500] loss = 3.1415 (policy = 2.6003  value = 0.5412) (val acc:  30.5%)\n",
      "( 1560.4) [ 350000] loss = 3.1452 (policy = 2.6075  value = 0.5376) (val acc:  30.6%)\n",
      "( 1571.8) [ 352500] loss = 3.1347 (policy = 2.5966  value = 0.5381) (val acc:  30.6%)\n",
      "( 1583.2) [ 355000] loss = 3.1410 (policy = 2.6040  value = 0.5370) (val acc:  30.6%)\n",
      "( 1594.7) [ 357500] loss = 3.1462 (policy = 2.6032  value = 0.5430) (val acc:  30.6%)\n",
      "( 1606.1) [ 360000] loss = 3.1523 (policy = 2.6154  value = 0.5369) (val acc:  30.6%)\n",
      "( 1617.5) [ 362500] loss = 3.1406 (policy = 2.6013  value = 0.5393) (val acc:  30.4%)\n",
      "( 1628.8) [ 365000] loss = 3.1481 (policy = 2.6088  value = 0.5393) (val acc:  30.5%)\n",
      "( 1640.3) [ 367500] loss = 3.1471 (policy = 2.6087  value = 0.5385) (val acc:  30.5%)\n",
      "( 1651.6) [ 370000] loss = 3.1516 (policy = 2.6093  value = 0.5423) (val acc:  30.5%)\n",
      "( 1662.9) [ 372500] loss = 3.1460 (policy = 2.6070  value = 0.5390) (val acc:  30.5%)\n",
      "( 1674.3) [ 375000] loss = 3.1397 (policy = 2.5968  value = 0.5429) (val acc:  30.6%)\n",
      "( 1685.6) [ 377500] loss = 3.1469 (policy = 2.6045  value = 0.5424) (val acc:  30.6%)\n",
      "( 1696.9) [ 380000] loss = 3.1511 (policy = 2.6110  value = 0.5401) (val acc:  30.5%)\n",
      "( 1809.4) [ 405000] loss = 3.1417 (policy = 2.5995  value = 0.5422) (val acc:  30.5%)\n",
      "( 1820.3) [ 407500] loss = 3.1344 (policy = 2.5977  value = 0.5366) (val acc:  30.5%)\n",
      "( 1831.5) [ 410000] loss = 3.1306 (policy = 2.5923  value = 0.5383) (val acc:  30.5%)\n",
      "( 1843.1) [ 412500] loss = 3.1297 (policy = 2.5961  value = 0.5335) (val acc:  30.5%)\n",
      "( 1854.3) [ 415000] loss = 3.1351 (policy = 2.5967  value = 0.5384) (val acc:  30.5%)\n",
      "( 1865.4) [ 417500] loss = 3.1360 (policy = 2.5961  value = 0.5399) (val acc:  30.5%)\n",
      "( 1876.7) [ 420000] loss = 3.1428 (policy = 2.6062  value = 0.5366) (val acc:  30.4%)\n",
      "( 1887.9) [ 422500] loss = 3.1449 (policy = 2.6042  value = 0.5407) (val acc:  30.6%)\n",
      "( 1898.8) [ 425000] loss = 3.1441 (policy = 2.6027  value = 0.5414) (val acc:  30.4%)\n",
      "( 1910.1) [ 427500] loss = 3.1465 (policy = 2.6075  value = 0.5390) (val acc:  30.5%)\n",
      "( 1921.2) [ 430000] loss = 3.1583 (policy = 2.6144  value = 0.5439) (val acc:  30.6%)\n",
      "( 1932.2) [ 432500] loss = 3.1342 (policy = 2.5935  value = 0.5407) (val acc:  30.5%)\n",
      "( 1943.5) [ 435000] loss = 3.1450 (policy = 2.6006  value = 0.5444) (val acc:  30.5%)\n",
      "( 1954.7) [ 437500] loss = 3.1367 (policy = 2.5995  value = 0.5372) (val acc:  30.5%)\n",
      "( 1965.8) [ 440000] loss = 3.1439 (policy = 2.6057  value = 0.5382) (val acc:  30.5%)\n",
      "( 1976.8) [ 442500] loss = 3.1347 (policy = 2.5923  value = 0.5424) (val acc:  30.6%)\n",
      "( 1988.1) [ 445000] loss = 3.1413 (policy = 2.6000  value = 0.5413) (val acc:  30.4%)\n",
      "( 1999.2) [ 447500] loss = 3.1461 (policy = 2.6063  value = 0.5397) (val acc:  30.4%)\n",
      "( 2010.3) [ 450000] loss = 3.1431 (policy = 2.6026  value = 0.5405) (val acc:  30.4%)\n",
      "( 2021.7) [ 452500] loss = 3.1410 (policy = 2.6000  value = 0.5410) (val acc:  30.6%)\n",
      "( 2032.9) [ 455000] loss = 3.1311 (policy = 2.5908  value = 0.5404) (val acc:  30.5%)\n",
      "( 2044.3) [ 457500] loss = 3.1505 (policy = 2.6113  value = 0.5392) (val acc:  30.5%)\n",
      "( 2055.6) [ 460000] loss = 3.1352 (policy = 2.5990  value = 0.5362) (val acc:  30.7%)\n",
      "( 2066.7) [ 462500] loss = 3.1378 (policy = 2.5980  value = 0.5398) (val acc:  30.6%)\n",
      "( 2078.0) [ 465000] loss = 3.1373 (policy = 2.5959  value = 0.5414) (val acc:  30.7%)\n",
      "( 2089.3) [ 467500] loss = 3.1361 (policy = 2.5954  value = 0.5406) (val acc:  30.6%)\n",
      "( 2100.3) [ 470000] loss = 3.1515 (policy = 2.6088  value = 0.5427) (val acc:  30.5%)\n",
      "( 2111.3) [ 472500] loss = 3.1292 (policy = 2.5913  value = 0.5379) (val acc:  30.7%)\n",
      "( 2122.8) [ 475000] loss = 3.1376 (policy = 2.5899  value = 0.5477) (val acc:  30.6%)\n",
      "( 2133.9) [ 477500] loss = 3.1409 (policy = 2.5974  value = 0.5435) (val acc:  30.6%)\n",
      "( 2145.0) [ 480000] loss = 3.1432 (policy = 2.6034  value = 0.5398) (val acc:  30.5%)\n",
      "( 2156.3) [ 482500] loss = 3.1412 (policy = 2.5966  value = 0.5446) (val acc:  30.7%)\n",
      "( 2167.5) [ 485000] loss = 3.1355 (policy = 2.5991  value = 0.5365) (val acc:  30.5%)\n",
      "( 2178.7) [ 487500] loss = 3.1440 (policy = 2.6031  value = 0.5409) (val acc:  30.6%)\n",
      "( 2190.0) [ 490000] loss = 3.1381 (policy = 2.5952  value = 0.5429) (val acc:  30.6%)\n",
      "( 2201.4) [ 492500] loss = 3.1397 (policy = 2.5969  value = 0.5428) (val acc:  30.5%)\n",
      "( 2212.5) [ 495000] loss = 3.1325 (policy = 2.5855  value = 0.5471) (val acc:  30.6%)\n",
      "( 2223.4) [ 497500] loss = 3.1408 (policy = 2.6053  value = 0.5355) (val acc:  30.6%)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_744856/2831864494.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mpolicy_loss_ewma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mvalue_loss_ewma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             adamw(params_with_grad,\n\u001b[0m\u001b[1;32m    162\u001b[0m                   \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                   \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adamw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    219\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dm_val_which_model = 2 * val_is_duck_move + (1 - val_is_white_turn)\n",
    "\n",
    "def make_batch(batch_size):\n",
    "    indices = np.random.randint(0, len(dm_features), size=batch_size)\n",
    "    features = torch.tensor(dm_features[indices], dtype=torch.float32, device=device)\n",
    "    policy = torch.tensor(dm_policy[indices], dtype=torch.int64, device=device)\n",
    "    value = torch.tensor(dm_value[indices], dtype=torch.float32, device=device)\n",
    "    which_model = torch.tensor(\n",
    "        2 * is_duck_move[indices] + (1 - is_white_turn[indices]),\n",
    "        dtype=torch.int64,\n",
    "        device=device,\n",
    "    )\n",
    "    return features, policy, value, which_model\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(1_000_000):\n",
    "    optimizer.zero_grad()\n",
    "    features, target_policy, target_value, which_model = make_batch(512)\n",
    "    policy_output, value_output = model(features, which_model)\n",
    "    policy_loss = cross_en(policy_output, target_policy)\n",
    "    value_loss = mse_func(value_output, target_value)\n",
    "    loss = policy_loss + value_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    policy_loss_ewma.apply(policy_loss.item())\n",
    "    value_loss_ewma.apply(value_loss.item())\n",
    "\n",
    "    if i % 2500 == 0:\n",
    "        # Compute the accuracy.\n",
    "        val_policy_output, val_value_output = model(dm_val_features, dm_val_which_model)\n",
    "        correct = val_policy_output.argmax(axis=-1) == dm_val_policy\n",
    "        accuracy = correct.mean(dtype=torch.float32).item()\n",
    "        print(\"(%7.1f) [%7i] loss = %.4f (policy = %.4f  value = %0.4f) (val acc: %5.1f%%)\" % (\n",
    "            time.time() - start_time,\n",
    "            i,\n",
    "            policy_loss_ewma.value + value_loss_ewma.value,\n",
    "            policy_loss_ewma.value,\n",
    "            value_loss_ewma.value,\n",
    "            100 * accuracy,\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55bea8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"multi-model-feat128-64-003.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de50b3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), \"move_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d584062d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight torch.Size([32, 1472])\n",
      "0.bias torch.Size([32])\n",
      "2.weight torch.Size([64, 32])\n",
      "2.bias torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for k, v in model.state_dict().items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b9062c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = model.state_dict()[\"0.weight\"].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94bc035f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(W.flatten(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b845cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8015668"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(W).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e979387",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wi = (W * 1000).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b901650b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2,    7,    0, ..., -625, -385, -311],\n",
       "       [ -14,   -7,  -13, ...,  326,   56, -207],\n",
       "       [  -5,   17,  -10, ..., -622, -306, -556],\n",
       "       ...,\n",
       "       [   6,    3,  -13, ...,  -70,  -71, -163],\n",
       "       [   6,  -10,    6, ..., -414, -375, -323],\n",
       "       [  13,  -17,  -16, ..., -288,   17,  -83]], dtype=int32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wi"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7772764",
   "metadata": {},
   "source": [
    "Performance:\n",
    "features -> 64                   --  29.5%\n",
    "features -> 64 -> 64             --  32.1%\n",
    "features -> 128 -> 64            --  35.7%\n",
    "features -> 128 -> 128 -> 64     --  35.9%\n",
    "features -> 1024 -> 64           --  40.8%\n",
    "features -> 48 -> 96 -> 96 -> 64 --  31.7%\n",
    "features -> 32 -> 64             --  27.1%\n",
    "features -> 32 -> 96 -> 64       --  29.0%\n",
    "\n",
    "New performances (four networks, both move kinds):\n",
    "features -> 64 -> 64 -> 65       --  31.5%\n",
    "features -> 64 -> 65             --  29.5%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0dbcc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "cases = 4\n",
    "features = 64\n",
    "\n",
    "# Generate some fake data.\n",
    "data = torch.tensor(np.random.randn(cases, batch_size, features))\n",
    "idx = torch.tensor(np.random.randint(low=0, high=cases, size=batch_size))\n",
    "\n",
    "# Index into the data of shape [batch_size, cases, features], getting a result of shape [batch_size, features].\n",
    "# This is the same as:\n",
    "#   result = np.zeros((batch_size, features))\n",
    "#   for i in range(batch_size):\n",
    "#       result[i] = data[i, idx[i]]\n",
    "result = data[idx, torch.arange(batch_size)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79a66550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 64])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4716e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 1, 2, 1, 1, 1, 0, 1, 0, 3, 1, 0, 0, 0, 2, 2, 2, 1, 1, 0, 0, 3, 3, 3,\n",
       "        1, 1, 1, 3, 0, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "234bf354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0] == data[3, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b69de53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
