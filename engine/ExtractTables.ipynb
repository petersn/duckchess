{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8cac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a66999",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"multi-model-nonsense.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b48194",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e03d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_scale_i8 = 150\n",
    "integer_scale_i16 = 5_000\n",
    "\n",
    "code = [\n",
    "    \"// Automatically generated by ExtractTables.ipynb\\n\\n\"\n",
    "    \"pub const INTEGER_SCALE_I8: f32 = %.1f;\\n\" % integer_scale_i8,\n",
    "    \"pub const INTEGER_SCALE_I16: f32 = %.1f;\\n\" % integer_scale_i16,\n",
    "    \"#[repr(C)]\\nstruct SixteenByteAligned<T> {\\n  _align: [u128; 0],\\n  data: T,\\n}\\n\",\n",
    "]\n",
    "\n",
    "for weight_name, weight in model.items():\n",
    "    print(\"  Weight:\", weight_name, weight.shape)\n",
    "    name = \"PARAMS_\" + weight_name.replace(\".\", \"_\").upper()\n",
    "    # Hack to rename layers. FIXME: This should be part of the model itself.\n",
    "    name = name.replace(\"2\", \"1\").replace(\"4\", \"2\")\n",
    "    \n",
    "    if \"bias\" in weight_name:\n",
    "        weight = (integer_scale_i16 * weight).to(torch.int32)\n",
    "        type_name = \"i16\"\n",
    "        array = \" \".join(\"%i\" % x + \",\" for x in weight)\n",
    "        code.append(\n",
    "            f\"pub static {name}: &'static [{type_name}; {weight.shape[0]}] = &DUMMY_{name}.data;\\n\"\n",
    "        )\n",
    "        code.append(\n",
    "            f\"static DUMMY_{name}: SixteenByteAligned<[{type_name}; {weight.shape[0]}]>\"\n",
    "            f\" = SixteenByteAligned {{\\n  _align: [],\\n  data: [\\n  {array}\\n  ],\\n}};\\n\"\n",
    "        )\n",
    "        continue\n",
    "    elif weight_name == \"main_embed.weight\":\n",
    "        # Transpose only the very first weight.\n",
    "        weight = weight.T\n",
    "        weight = (integer_scale_i16 * weight).to(torch.int32)\n",
    "        type_name = \"i16\"\n",
    "    else:\n",
    "        weight = (integer_scale_i8 * weight).to(torch.int32)\n",
    "        type_name = \"i8\"\n",
    "    array = \"\\n\".join(\n",
    "        \"  [\" + \", \".join(\"%i\" % x for x in row) + \"],\"\n",
    "        for row in weight\n",
    "    )\n",
    "    code.append(\n",
    "            f\"pub static {name}: &'static [[{type_name}; {weight.shape[1]}]; {weight.shape[0]}] = &DUMMY_{name}.data;\\n\"\n",
    "        )\n",
    "    #code.append(\"pub static %s: &'static [[%s; %i]; %i] = &[\\n%s\\n];\\n\" % (\n",
    "    code.append(\n",
    "        f\"static DUMMY_{name}: SixteenByteAligned<[[{type_name}; {weight.shape[1]}]; {weight.shape[0]}]>\"\n",
    "        f\" = SixteenByteAligned {{\\n  _align: [],\\n  data: [\\n  {array}\\n  ],\\n}};\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfebcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"src/nnue_data.rs\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(code))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7610023a",
   "metadata": {},
   "source": [
    "# Debug incorrect outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d234f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_up_features(feats):\n",
    "    _, a, b, c = feats.shape\n",
    "    assert (a, b, c) == (15, 8, 8)\n",
    "    # feats of shape [batch, 15, 8, 8]\n",
    "    # is_white_turn of shape [batch]\n",
    "    is_white_turn = feats[:, -2, 0, 0]\n",
    "    \n",
    "    # If we're black then they're in order (black pieces black bottom, white pieces black bottom)\n",
    "    # We want to convert this into (black pieces white bottom, white pieces white bottom)\n",
    "    if_black = feats[:, :-2].copy()\n",
    "    if_black[:, :, :, :] = feats[:, :-2, ::-1, :]\n",
    "\n",
    "    # If we're white then they're in the order (white pieces white bottom, black pieces, white bottom)\n",
    "    # We want to just swap the two halves.\n",
    "    if_white = feats[:, :-2].copy()\n",
    "    if_white[:, :6, :, :] = feats[:, 6:12, :, :]\n",
    "    if_white[:, 6:12, :, :] = feats[:, :6, :, :]\n",
    "\n",
    "    return np.where(\n",
    "        is_white_turn.reshape(-1, 1, 1, 1),\n",
    "        if_white,\n",
    "        if_black,\n",
    "    ).reshape(-1, 13 * 8 * 8)\n",
    "\n",
    "feature_count = 13 * 64\n",
    "\n",
    "class MultiModel(torch.nn.Module):\n",
    "    FEATS = 64\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main_embed = torch.nn.Linear(feature_count, self.FEATS)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        self.white_main = torch.nn.Linear(self.FEATS, 64 + 1)\n",
    "        self.black_main = torch.nn.Linear(self.FEATS, 64 + 1)\n",
    "        self.white_duck = torch.nn.Linear(self.FEATS, 64 + 1)\n",
    "        self.black_duck = torch.nn.Linear(self.FEATS, 64 + 1)\n",
    "\n",
    "    def forward(self, inputs, which_model):\n",
    "        embedding = self.main_embed(inputs)\n",
    "        embedding = self.relu(embedding)\n",
    "        white_main = self.white_main(embedding)\n",
    "        black_main = self.black_main(embedding)\n",
    "        white_duck = self.white_duck(embedding)\n",
    "        black_duck = self.black_duck(embedding)\n",
    "        data = torch.stack([white_main, black_main, white_duck, black_duck])\n",
    "        data = data[which_model, torch.arange(len(which_model))]\n",
    "        policy = data[:, :64]\n",
    "        value = data[:, 64:]\n",
    "        return policy, value, embedding\n",
    "\n",
    "model = MultiModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fc7483",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"multi-model-feat64-002.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225876d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_val = np.load(\"dm_val.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ad6910",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = patch_up_features(dm_val[\"features\"].reshape(-1, 15, 8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5c66ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.reshape(-1, 13, 8, 8)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dd3fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_feat = f[0].copy().reshape(13, 8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a61d7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "starting_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf794b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_feat[6, 1, 1] = 1\n",
    "starting_feat[6, 2, 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b264a46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463eb4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = model(\n",
    "    torch.tensor(starting_feat.reshape(1, -1), dtype=torch.float32),\n",
    "    torch.tensor([0]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3b39ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79297f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(a.reshape(8, 8).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717bbd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_linear_state = (c - model.state_dict()[\"main_embed.bias\"]).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17108d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(target_linear_state.reshape(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be30289",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(initial_linear_state.reshape(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291d0373",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_linear_state - initial_linear_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b094026",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial_linear_state = np.array([120001, 383580, 137398, 283756, 509098, 558127, -12455, 80365, 53778, 28397, -212367, 404435, 60373, 181293, 335118, -277217, 60015, 86152, 57077, -66096, -178402, -244652, 218425, 148898, -4227, -96644, -260137, 223537, 9941, 265566, 22002, 113431, -436525, 49648, -158136, -279139, 16615, 292464, -995, 141168, 28381, 177354, 466708, 105724, 8724, 162147, 426389, -41261, 114401, 169764, -323398, 50508, -32995, 384948, -163998, 207688, 111465, 23619, 168553, 257046, -323129, -294584, 333272, -362578])\n",
    "initial_linear_state = np.array([208542, 74304, 103035, 177503, 99221, 99967, 49951, 122207, 126187, 64259, 159768, 151716, 140049, 161754, 193359, 5650, 123477, 134962, 280206, 61696, 169496, 112387, 147432, 49673, 58197, 83177, 200995, 156319, 83740, 49658, 178320, 140592, 29850, 120040, 86116, 102971, 214913, 83073, 147879, 166541, 11799, 143009, 47335, 123813, 119054, 147022, 141939, 145978, 265811, 151486, 73656, 147084, 177416, 142320, 194774, 206018, 196784, 89110, 148636, 182453, 128863, 137679, 165823, 47865])\n",
    "initial_linear_state = initial_linear_state.astype(np.float64)\n",
    "initial_linear_state /= integer_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5a4f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_linear_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7295f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
