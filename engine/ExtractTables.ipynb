{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b8cac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09a66999",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"multi-model-nonsense.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96b48194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['main_embed.weight', 'main_embed.bias', 'white_main.0.weight', 'white_main.0.bias', 'white_main.2.weight', 'white_main.2.bias', 'white_main.4.weight', 'white_main.4.bias', 'black_main.0.weight', 'black_main.0.bias', 'black_main.2.weight', 'black_main.2.bias', 'black_main.4.weight', 'black_main.4.bias', 'white_duck.0.weight', 'white_duck.0.bias', 'white_duck.2.weight', 'white_duck.2.bias', 'white_duck.4.weight', 'white_duck.4.bias', 'black_duck.0.weight', 'black_duck.0.bias', 'black_duck.2.weight', 'black_duck.2.bias', 'black_duck.4.weight', 'black_duck.4.bias'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33e03d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Weight: main_embed.weight torch.Size([256, 960])\n",
      "  Weight: main_embed.bias torch.Size([256])\n",
      "  Weight: white_main.0.weight torch.Size([16, 256])\n",
      "  Weight: white_main.0.bias torch.Size([16])\n",
      "  Weight: white_main.2.weight torch.Size([32, 16])\n",
      "  Weight: white_main.2.bias torch.Size([32])\n",
      "  Weight: white_main.4.weight torch.Size([1, 32])\n",
      "  Weight: white_main.4.bias torch.Size([1])\n",
      "  Weight: black_main.0.weight torch.Size([16, 256])\n",
      "  Weight: black_main.0.bias torch.Size([16])\n",
      "  Weight: black_main.2.weight torch.Size([32, 16])\n",
      "  Weight: black_main.2.bias torch.Size([32])\n",
      "  Weight: black_main.4.weight torch.Size([1, 32])\n",
      "  Weight: black_main.4.bias torch.Size([1])\n",
      "  Weight: white_duck.0.weight torch.Size([16, 256])\n",
      "  Weight: white_duck.0.bias torch.Size([16])\n",
      "  Weight: white_duck.2.weight torch.Size([32, 16])\n",
      "  Weight: white_duck.2.bias torch.Size([32])\n",
      "  Weight: white_duck.4.weight torch.Size([1, 32])\n",
      "  Weight: white_duck.4.bias torch.Size([1])\n",
      "  Weight: black_duck.0.weight torch.Size([16, 256])\n",
      "  Weight: black_duck.0.bias torch.Size([16])\n",
      "  Weight: black_duck.2.weight torch.Size([32, 16])\n",
      "  Weight: black_duck.2.bias torch.Size([32])\n",
      "  Weight: black_duck.4.weight torch.Size([1, 32])\n",
      "  Weight: black_duck.4.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "integer_scale_i8 = 150\n",
    "integer_scale_i16 = 5_000\n",
    "\n",
    "code = [\n",
    "    \"// Automatically generated by ExtractTables.ipynb\\n\\n\"\n",
    "    \"pub const INTEGER_SCALE_I8: f32 = %.1f;\\n\" % integer_scale_i8,\n",
    "    \"pub const INTEGER_SCALE_I16: f32 = %.1f;\\n\" % integer_scale_i16,\n",
    "    \"#[repr(C)]\\nstruct SixteenByteAligned<T> {\\n  _align: [u128; 0],\\n  data: T,\\n}\\n\",\n",
    "]\n",
    "\n",
    "for weight_name, weight in model.items():\n",
    "    print(\"  Weight:\", weight_name, weight.shape)\n",
    "    name = \"PARAMS_\" + weight_name.replace(\".\", \"_\").upper()\n",
    "    # Hack to rename layers. FIXME: This should be part of the model itself.\n",
    "    name = name.replace(\"2\", \"1\").replace(\"4\", \"2\")\n",
    "    if weight_name == \"main_embed.weight\":\n",
    "        # Transpose only the very first weight.\n",
    "        weight = weight.T\n",
    "    if \"bias\" in weight_name:\n",
    "        weight = (integer_scale_i16 * weight).to(torch.int32)\n",
    "        type_name = \"i16\"\n",
    "        array = \" \".join(\"%i\" % x + \",\" for x in weight)\n",
    "        code.append(\n",
    "            f\"pub static {name}: &'static [{type_name}; {weight.shape[0]}] = &DUMMY_{name}.data;\\n\"\n",
    "        )\n",
    "        code.append(\n",
    "            f\"static DUMMY_{name}: SixteenByteAligned<[{type_name}, {weight.shape[0]}]>\"\n",
    "            f\" = SixteenByteAligned {{\\n  _align: [],\\n  data: [\\n  {array}\\n  ],\\n}};\\n\"\n",
    "        )\n",
    "        continue\n",
    "    else:\n",
    "        weight = (integer_scale_i8 * weight).to(torch.int32)\n",
    "        type_name = \"i8\"\n",
    "    array = \"\\n\".join(\n",
    "        \"  [\" + \", \".join(\"%i\" % x for x in row) + \"],\"\n",
    "        for row in weight\n",
    "    )\n",
    "    code.append(\n",
    "            f\"pub static {name}: &'static [[{type_name}; {weight.shape[1]}] {weight.shape[0]}] = &DUMMY_{name}.data\\n\"\n",
    "        )\n",
    "    #code.append(\"pub static %s: &'static [[%s; %i]; %i] = &[\\n%s\\n];\\n\" % (\n",
    "    code.append(\n",
    "        f\"static DUMMY_{name}: SixteenByteAligned<[[{type_name}; {weight.shape[1]}], {weight.shape[0]}]>\"\n",
    "        f\" = SixteenByteAligned {{\\n  _align: [],\\n  data: [\\n  {array}\\n  ],\\n}};\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dfebcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"src/nnue_data.rs\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(code))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7610023a",
   "metadata": {},
   "source": [
    "# Debug incorrect outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d234f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_up_features(feats):\n",
    "    _, a, b, c = feats.shape\n",
    "    assert (a, b, c) == (15, 8, 8)\n",
    "    # feats of shape [batch, 15, 8, 8]\n",
    "    # is_white_turn of shape [batch]\n",
    "    is_white_turn = feats[:, -2, 0, 0]\n",
    "    \n",
    "    # If we're black then they're in order (black pieces black bottom, white pieces black bottom)\n",
    "    # We want to convert this into (black pieces white bottom, white pieces white bottom)\n",
    "    if_black = feats[:, :-2].copy()\n",
    "    if_black[:, :, :, :] = feats[:, :-2, ::-1, :]\n",
    "\n",
    "    # If we're white then they're in the order (white pieces white bottom, black pieces, white bottom)\n",
    "    # We want to just swap the two halves.\n",
    "    if_white = feats[:, :-2].copy()\n",
    "    if_white[:, :6, :, :] = feats[:, 6:12, :, :]\n",
    "    if_white[:, 6:12, :, :] = feats[:, :6, :, :]\n",
    "\n",
    "    return np.where(\n",
    "        is_white_turn.reshape(-1, 1, 1, 1),\n",
    "        if_white,\n",
    "        if_black,\n",
    "    ).reshape(-1, 13 * 8 * 8)\n",
    "\n",
    "feature_count = 13 * 64\n",
    "\n",
    "class MultiModel(torch.nn.Module):\n",
    "    FEATS = 64\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main_embed = torch.nn.Linear(feature_count, self.FEATS)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        self.white_main = torch.nn.Linear(self.FEATS, 64 + 1)\n",
    "        self.black_main = torch.nn.Linear(self.FEATS, 64 + 1)\n",
    "        self.white_duck = torch.nn.Linear(self.FEATS, 64 + 1)\n",
    "        self.black_duck = torch.nn.Linear(self.FEATS, 64 + 1)\n",
    "\n",
    "    def forward(self, inputs, which_model):\n",
    "        embedding = self.main_embed(inputs)\n",
    "        embedding = self.relu(embedding)\n",
    "        white_main = self.white_main(embedding)\n",
    "        black_main = self.black_main(embedding)\n",
    "        white_duck = self.white_duck(embedding)\n",
    "        black_duck = self.black_duck(embedding)\n",
    "        data = torch.stack([white_main, black_main, white_duck, black_duck])\n",
    "        data = data[which_model, torch.arange(len(which_model))]\n",
    "        policy = data[:, :64]\n",
    "        value = data[:, 64:]\n",
    "        return policy, value, embedding\n",
    "\n",
    "model = MultiModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27fc7483",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'multi-model-feat64-002.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmulti-model-feat64-002.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    697\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 699\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'multi-model-feat64-002.pt'"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"multi-model-feat64-002.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225876d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_val = np.load(\"dm_val.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ad6910",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = patch_up_features(dm_val[\"features\"].reshape(-1, 15, 8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5c66ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.reshape(-1, 13, 8, 8)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dd3fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_feat = f[0].copy().reshape(13, 8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a61d7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "starting_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf794b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_feat[6, 1, 1] = 1\n",
    "starting_feat[6, 2, 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b264a46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463eb4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = model(\n",
    "    torch.tensor(starting_feat.reshape(1, -1), dtype=torch.float32),\n",
    "    torch.tensor([0]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3b39ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79297f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(a.reshape(8, 8).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717bbd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_linear_state = (c - model.state_dict()[\"main_embed.bias\"]).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17108d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(target_linear_state.reshape(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be30289",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(initial_linear_state.reshape(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291d0373",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_linear_state - initial_linear_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b094026",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial_linear_state = np.array([120001, 383580, 137398, 283756, 509098, 558127, -12455, 80365, 53778, 28397, -212367, 404435, 60373, 181293, 335118, -277217, 60015, 86152, 57077, -66096, -178402, -244652, 218425, 148898, -4227, -96644, -260137, 223537, 9941, 265566, 22002, 113431, -436525, 49648, -158136, -279139, 16615, 292464, -995, 141168, 28381, 177354, 466708, 105724, 8724, 162147, 426389, -41261, 114401, 169764, -323398, 50508, -32995, 384948, -163998, 207688, 111465, 23619, 168553, 257046, -323129, -294584, 333272, -362578])\n",
    "initial_linear_state = np.array([208542, 74304, 103035, 177503, 99221, 99967, 49951, 122207, 126187, 64259, 159768, 151716, 140049, 161754, 193359, 5650, 123477, 134962, 280206, 61696, 169496, 112387, 147432, 49673, 58197, 83177, 200995, 156319, 83740, 49658, 178320, 140592, 29850, 120040, 86116, 102971, 214913, 83073, 147879, 166541, 11799, 143009, 47335, 123813, 119054, 147022, 141939, 145978, 265811, 151486, 73656, 147084, 177416, 142320, 194774, 206018, 196784, 89110, 148636, 182453, 128863, 137679, 165823, 47865])\n",
    "initial_linear_state = initial_linear_state.astype(np.float64)\n",
    "initial_linear_state /= integer_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5a4f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_linear_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7295f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
